{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import sys\n",
    "load_dotenv(sys.path[0]+'/.env')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm=OpenAI(temperature=0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\nThe capital of India is New Delhi.'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"What is the capital of india\"\n",
    "llm.invoke(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import HuggingFaceHub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jyoti/Documents/Yogesh Study Material/Learning2024/GenAI/generative-ai/myenv/lib/python3.9/site-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The class `langchain_community.llms.huggingface_hub.HuggingFaceHub` was deprecated in langchain-community 0.0.21 and will be removed in 0.2.0. Use HuggingFaceEndpoint instead.\n",
      "  warn_deprecated(\n",
      "/Users/jyoti/Documents/Yogesh Study Material/Learning2024/GenAI/generative-ai/myenv/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "llm_huggingface = HuggingFaceHub(repo_id=\"google/flan-t5-large\", \n",
    "                    model_kwargs={\"temperature\":0, \"max_length\": 64})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jyoti/Documents/Yogesh Study Material/Learning2024/GenAI/generative-ai/myenv/lib/python3.9/site-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The function `predict` was deprecated in LangChain 0.1.7 and will be removed in 0.2.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'adelaide'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output=llm_huggingface.predict(\"Can you tell me the capital of Australia\")\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'math is a science that i love it i love it i love it i love it i love it i love it i love it i love it i love it i love it i love it i love it i love it i love it '"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output=llm_huggingface.predict(\"Can you write a poem about Mathematics\")\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n\\nMathematics, the language of numbers and shapes\\nA subject that often leaves us in a daze\\nBut oh, the beauty it holds within\\nA world of logic and patterns, where wonders begin\\n\\nFrom simple addition to complex equations\\nIt challenges our minds, igniting our imaginations\\nWith formulas and theorems, it never fails\\nTo amaze us with its endless trails\\n\\nIt's the language of science, the backbone of technology\\nWithout it, we'd be lost in a sea of ambiguity\\nIt measures the world, from the stars up above\\nTo the tiniest atoms, with precision and love\\n\\nIt's the bridge between art and science, a perfect blend\\nCreating symmetry and balance, from start to end\\nIn music and art, its presence is clear\\nIn nature and architecture, it's always near\\n\\nIt's a tool for problem-solving, a skill for life\\nTeaching us perseverance and how to thrive\\nIn a world full of chaos, it brings order and reason\\nA constant in our lives, through every season\\n\\nSo let us embrace, this subject of wonder\\nFor it's more than just numbers, it's a journey to ponder\\nMathematics, a never-ending quest\\nA beautiful symphony, that we\""
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.predict(\"Can you write a poem about Mathematics\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chat Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema import HumanMessage, SystemMessage, AIMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x111554f40>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x1115c4520>, temperature=0.6, openai_api_key=SecretStr('**********'), openai_proxy='')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chatllm=ChatOpenAI(temperature=0.6, model=\"gpt-3.5-turbo\")\n",
    "chatllm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='1. Why was the equal sign so humble? Because he knew he wasn\\'t less than or greater than anyone else.\\n2. Parallel lines have so much in common. It\\'s a shame they\\'ll never meet.\\n3. I asked my math teacher to stop telling us to find x. He said, \"No worries, we\\'ll find y instead.\"\\n4. Why was the math book sad? It had too many problems.\\n5. I told my friend I was terrible at math. He said, \"Don\\'t worry, even a calculator can\\'t solve your problems.\"\\n6. My algebra textbook threw itself out the window. It couldn\\'t handle all the problems.\\n7. I used to hate math, but then I realized decimals have a point.\\n8. Why was the geometry book always in a rush? It had too many angles to cover.\\n9. I failed my math test so many times, I thought I was destined to be a statistic.\\n10. I\\'m not a mathematician, but I\\'m pretty good at division. I can divide a pizza into equal slices like a pro.')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chatllm([\n",
    "SystemMessage(content=\"You are a comedian AI assistant\"),\n",
    "HumanMessage(content=\"Please provide some comedy puchlines on mathematics\"),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prompt Template + LLM + Output Parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.prompts.chat import ChatPromptTemplate\n",
    "from langchain.schema import BaseOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CommaSeparatedOutput(BaseOutputParser):\n",
    "    def parse(self, text:str):\n",
    "        return text.strip().split(\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"You are a helpful assistant. Whenever user gives an input, you should be able to generate 5 comma separated words synonyms to the input\"\n",
    "human_template=\"{text}\"\n",
    "chat_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", template),\n",
    "    (\"human\", human_template)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain=chat_prompt|chatllm|CommaSeparatedOutput()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['smart', ' clever', ' bright', ' sharp', ' astute']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"text\": \"intelligent\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
